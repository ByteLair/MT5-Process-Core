services:
  api:
    ports:
      - "${API_PORT:-8001}:8001"
    volumes:
      - models_mt5:/models
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  ml-scheduler:
    build:
      context: .
      dockerfile: ml/Dockerfile
    command: python -u ml/scheduler.py
    depends_on:
      db:
        condition: service_healthy
    env_file: [.env]
    environment:
      DATABASE_URL: "postgresql+psycopg://trader:trader123@db:5432/mt5_trading"
      ML_SYMBOL: "EURUSD"
      ML_TIMEFRAME: "H1"
      OMP_NUM_THREADS: "28"
      OPENBLAS_NUM_THREADS: "28"
      MKL_NUM_THREADS: "28"
      NUMEXPR_NUM_THREADS: "28"
      PYTORCH_NUM_THREADS: "28"
      OMP_PROC_BIND: "true"
      OMP_PLACES: "cores"
      KMP_AFFINITY: "granularity=fine,compact,1,0"
      MKL_DYNAMIC: "FALSE"
    volumes:
      - ./ml:/app/ml:rw
      - models_mt5:/models
    restart: unless-stopped
    # Use full server resources for CPU-bound scheduler if needed
    cpus: 28
    cpuset: "0-27"
    mem_limit: 32g
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  ml-trainer:
    build:
      context: .
      dockerfile: ml/Dockerfile
    # Use base compose command (prepare_dataset.py) to generate dataset and pass healthcheck
    depends_on:
      db:
        condition: service_healthy
    env_file: [.env]
    volumes:
      - models_mt5:/models
    restart: "no"
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"

  pgadmin:
    ports:
      - "${PGADMIN_PORT:-5051}:80"

volumes:
  models_mt5:
    name: models_mt5
    external: true
