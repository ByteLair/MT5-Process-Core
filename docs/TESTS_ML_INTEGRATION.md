# Testes de ML e Integra√ß√£o

## üéØ Vis√£o Geral

Este documento descreve a infraestrutura de testes para os m√≥dulos de Machine Learning do projeto MT5 Trading, incluindo testes unit√°rios, de integra√ß√£o e avan√ßados para modelos Informer.

## üîß Configura√ß√£o do Ambiente

### Estrutura de Testes

```
ml/
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py          # Configura√ß√£o autom√°tica de sys.path
‚îÇ   ‚îú‚îÄ‚îÄ test_ml.py           # Testes b√°sicos (DB, treinamento, predi√ß√£o)
‚îÇ   ‚îú‚îÄ‚îÄ test_ml_extended.py  # Testes de features e utilidades
‚îÇ   ‚îî‚îÄ‚îÄ test_ml_advanced.py  # Testes avan√ßados (Informer, sequ√™ncias, performance)
‚îî‚îÄ‚îÄ worker/
    ‚îî‚îÄ‚îÄ train.py             # M√≥dulo de treinamento refatorado
```

### Depend√™ncias Instaladas

Todas as depend√™ncias ML foram instaladas via `ml/requirements.txt`:

- **torch >= 2.0.0** (com suporte CPU)
- pandas, numpy, scikit-learn
- SQLAlchemy, psycopg, psycopg2-binary
- pytest, pytest-cov
- joblib, APScheduler

### Banco de Dados

O projeto oferece **duas op√ß√µes de banco de dados** para testes:

#### Op√ß√£o 1: Docker Compose (Recomendado)

```bash
# Porta 5432 j√° exposta no docker-compose.yml
docker-compose up -d db
export DATABASE_URL="postgresql+psycopg://trader:trader123@localhost:5432/mt5_trading"
```

#### Op√ß√£o 2: Terraform (Isolado)

```bash
# Provisionado na porta 5433 para evitar conflitos
cd infra/terraform
terraform apply
export DATABASE_URL="postgresql+psycopg://trader:trader123@localhost:5433/mt5_trading"
```

### Vari√°veis de Ambiente

```bash
# Obrigat√≥rio para testes de integra√ß√£o
export DATABASE_URL="postgresql+psycopg://trader:trader123@localhost:5432/mt5_trading"

# Opcional: customizar diret√≥rio de logs (padr√£o: ./logs/ml/)
export LOG_DIR="./logs/ml/"

# Opcional: customizar diret√≥rio de modelos (padr√£o: ./models)
export MODELS_DIR="./models"
```

## üöÄ Como Rodar os Testes

### Setup Inicial (Uma Vez)

```bash
# Ativar ambiente virtual
source .venv/bin/activate

# Instalar depend√™ncias ML
pip install -r ml/requirements.txt

# Iniciar banco de dados
docker-compose up -d db
```

### Execu√ß√£o de Testes

#### Todos os Testes ML

```bash
# N√£o √© mais necess√°rio exportar PYTHONPATH!
# O conftest.py cuida disso automaticamente
pytest ml/tests --cov=ml --cov-report=term --cov-report=xml
```

#### Testes Espec√≠ficos

```bash
# Apenas testes b√°sicos
pytest ml/tests/test_ml.py -v

# Apenas testes estendidos
pytest ml/tests/test_ml_extended.py -v

# Apenas testes avan√ßados (Informer)
pytest ml/tests/test_ml_advanced.py -v

# Excluir testes do Informer (mais r√°pido)
pytest ml/tests -k 'not informer' -v
```

#### Testes com Cobertura Detalhada

```bash
pytest ml/tests \
  --cov=ml \
  --cov-report=term-missing \
  --cov-report=html \
  --cov-report=xml \
  -v
```

## üìä O Que √â Testado

### Testes B√°sicos (`test_ml.py`)

- ‚úÖ Conex√£o com banco de dados (PostgreSQL/TimescaleDB)
- ‚úÖ Treinamento de modelo RandomForest
- ‚úÖ Salvamento e persist√™ncia de modelos (.pkl)
- ‚úÖ Predi√ß√£o com modelo treinado

### Testes Estendidos (`test_ml_extended.py`)

- ‚úÖ C√°lculo de RSI (Relative Strength Index)
- ‚úÖ Gera√ß√£o de features t√©cnicas (`make_features`)
- ‚úÖ Importa√ß√£o de m√≥dulos ML
- ‚úÖ Valida√ß√£o de vari√°veis de ambiente
- ‚úÖ Verifica√ß√£o de estrutura de diret√≥rios
- ‚úÖ Testes de avalia√ß√£o de threshold (quando schema dispon√≠vel)

### Testes Avan√ßados (`test_ml_advanced.py`)

- ‚úÖ Cria√ß√£o de sequ√™ncias temporais (Informer)
- ‚úÖ Feature engineering para modelos de s√©ries temporais
- ‚úÖ Casos extremos (RSI, pre√ßos constantes, NaN handling)
- ‚úÖ Engenharia de features abrangente
- ‚úÖ Propaga√ß√£o de NaN
- ‚úÖ Reprodutibilidade de treinamento
- ‚úÖ Persist√™ncia de modelos
- ‚úÖ Performance de feature engineering (benchmark < 5s para 10k linhas)

## üìà Cobertura Atual

### Estat√≠sticas de Testes

- **Total de Testes**: 19 aprovados, 1 pulado
- **Cobertura ML**: ~22% (melhorado de ~6% inicial)
- **Tempo de Execu√ß√£o**: ~6-10 minutos (incluindo testes Informer)

### Arquivos Cobertos

```
ml/worker/train.py           # Engine DB e fun√ß√µes de treinamento
ml/prepare_dataset.py        # RSI, features t√©cnicas
ml/train_informer_advanced.py # Sequ√™ncias, features Informer
ml/eval_threshold.py         # M√©tricas e thresholds (skip se schema ausente)
```

### Relat√≥rios Gerados

- `coverage.xml` - XML para integra√ß√£o CI/CD
- `htmlcov/` - Relat√≥rio HTML interativo
- Terminal - Resumo com linhas faltantes

## üîÑ Melhorias Implementadas

### 1. Refatora√ß√£o do M√≥dulo de Treinamento

**Arquivo**: `ml/worker/train.py`

**Problema Original**:

- Leitura do banco e treinamento executados no import
- Side effects causavam erros nos testes
- Engine criado mesmo quando n√£o necess√°rio

**Solu√ß√£o**:

```python
# Antes (execu√ß√£o no import)
df = pd.read_sql("SELECT * FROM trainset_m1", engine)
X = df[...].fillna(0)
m.fit(X, y)

# Depois (lazy execution)
def load_dataset(engine_):
    """Carrega dataset apenas quando chamado explicitamente."""
    return pd.read_sql("SELECT * FROM trainset_m1", engine_)

def train_and_save(df_local: pd.DataFrame) -> str:
    """Treina e salva modelo, retorna caminho."""
    # L√≥gica de treinamento

def main():
    df = load_dataset(engine)
    train_and_save(df)
```

**Benef√≠cios**:

- ‚úÖ Import r√°pido e sem side effects
- ‚úÖ Engine dispon√≠vel para testes (`from ml.worker.train import engine`)
- ‚úÖ Fun√ß√µes test√°veis isoladamente
- ‚úÖ Controle expl√≠cito de quando treinar

### 2. Configura√ß√£o Autom√°tica de Imports

**Arquivo**: `ml/tests/conftest.py`

**Problema Original**:

- Necess√°rio `export PYTHONPATH=.` antes de cada teste
- Imports falhavam: `ModuleNotFoundError: No module named 'ml'`

**Solu√ß√£o**:

```python
"""
Configura√ß√£o de testes do pacote ML.

Insere a raiz do reposit√≥rio no sys.path para permitir imports absolutos
como `from ml.worker.train import engine` sem precisar exportar PYTHONPATH.
"""
import os
import sys

def _ensure_repo_root_on_path() -> None:
    tests_dir = os.path.dirname(os.path.abspath(__file__))
    repo_root = os.path.abspath(os.path.join(tests_dir, os.pardir, os.pardir))
    if repo_root not in sys.path:
        sys.path.insert(0, repo_root)

_ensure_repo_root_on_path()
```

**Benef√≠cios**:

- ‚úÖ Testes funcionam direto: `pytest ml/tests`
- ‚úÖ Sem necessidade de configurar `PYTHONPATH`
- ‚úÖ Compat√≠vel com IDEs e CI/CD
- ‚úÖ Imports absolutos funcionam automaticamente

### 3. Instala√ß√£o Completa de Depend√™ncias ML

**A√ß√£o**: Instala√ß√£o de `ml/requirements.txt` com torch

```bash
pip install -r ml/requirements.txt --extra-index-url https://download.pytorch.org/whl/cpu
```

**Pacotes Instalados**:

- torch >= 2.0.0 (vers√£o CPU para CI/testes)
- Todas as depend√™ncias NVIDIA CUDA (para ambientes com GPU)
- triton (otimiza√ß√µes de kernel)

**Benef√≠cios**:

- ‚úÖ Testes avan√ßados de Informer funcionam
- ‚úÖ Modelo completo dispon√≠vel para desenvolvimento
- ‚úÖ CI pode rodar suite completa

## üêõ Problemas Conhecidos e Solu√ß√µes

### Teste Pulado: `test_eval_threshold_imports`

**Status**: Skip condicional quando schema n√£o existe

**Raz√£o**: Tabelas `features_h1` e `labels_h1` podem n√£o existir em banco vazio

**Solu√ß√£o**:

```python
@pytest.mark.skipif(
    not _check_db_tables_exist(),
    reason="Schema features_h1/labels_h1 n√£o existe no banco",
)
def test_eval_threshold_imports():
    from ml.eval_threshold import calculate_metrics
```

**Como Resolver**:

1. Popular banco com dados hist√≥ricos
2. Executar `prepare_dataset.py` para criar features
3. Reexecutar testes: o skip ser√° removido automaticamente

### Warnings de Deprecation

**Fonte**: SQLAlchemy 2.0 e numpy

**Status**: N√£o bloqueante, apenas informativos

**A√ß√£o**: Podem ser suprimidos com `--disable-warnings` ou corrigidos em sprint futuro

## üéØ Pr√≥ximos Passos

### Curto Prazo

1. **Lint e Type Check**
   - Executar `ruff check --fix ml` para corrigir imports
   - Executar `mypy ml` para valida√ß√£o de tipos
   - Integrar no CI para enforcement autom√°tico

2. **Atualiza√ß√£o de Docs**
   - Remover instru√ß√µes obsoletas de `PYTHONPATH`
   - Adicionar guia de troubleshooting
   - Documentar casos de uso de cada suite de testes

3. **Testes de API**
   - Criar `api/tests/test_integration.py`
   - Testar endpoints `/health`, `/predict`, `/signals`
   - Integrar com mesmo banco de testes
   - Adicionar ao CI

### M√©dio Prazo

1. **Expans√£o de Cobertura**
   - Meta: 60%+ de cobertura ML
   - Adicionar testes para `train_model.py`
   - Testar scheduler e workers
   - Validar pipeline completo end-to-end

2. **CI/CD Enhancement**
   - Badge de cobertura no README
   - Integra√ß√£o com Codecov/Coveralls
   - Testes paralelos para velocidade
   - Cache de depend√™ncias torch

3. **Performance Testing**
   - Benchmarks de treinamento
   - Testes de carga para API
   - Valida√ß√£o de mem√≥ria/CPU usage

---

# üåç ENGLISH VERSION

## üéØ Overview

This document describes the testing infrastructure for the MT5 Trading ML modules, including unit, integration, and advanced tests for Informer models.

## üîß Environment Setup

### Test Structure

```
ml/
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py          # Automatic sys.path configuration
‚îÇ   ‚îú‚îÄ‚îÄ test_ml.py           # Basic tests (DB, training, prediction)
‚îÇ   ‚îú‚îÄ‚îÄ test_ml_extended.py  # Feature and utility tests
‚îÇ   ‚îî‚îÄ‚îÄ test_ml_advanced.py  # Advanced tests (Informer, sequences, performance)
‚îî‚îÄ‚îÄ worker/
    ‚îî‚îÄ‚îÄ train.py             # Refactored training module
```

### Installed Dependencies

All ML dependencies installed via `ml/requirements.txt`:

- **torch >= 2.0.0** (CPU support)
- pandas, numpy, scikit-learn
- SQLAlchemy, psycopg, psycopg2-binary
- pytest, pytest-cov
- joblib, APScheduler

### Database Options

The project offers **two database options** for testing:

#### Option 1: Docker Compose (Recommended)

```bash
# Port 5432 already exposed in docker-compose.yml
docker-compose up -d db
export DATABASE_URL="postgresql+psycopg://trader:trader123@localhost:5432/mt5_trading"
```

#### Option 2: Terraform (Isolated)

```bash
# Provisioned on port 5433 to avoid conflicts
cd infra/terraform
terraform apply
export DATABASE_URL="postgresql+psycopg://trader:trader123@localhost:5433/mt5_trading"
```

### Environment Variables

```bash
# Required for integration tests
export DATABASE_URL="postgresql+psycopg://trader:trader123@localhost:5432/mt5_trading"

# Optional: customize log directory (default: ./logs/ml/)
export LOG_DIR="./logs/ml/"

# Optional: customize models directory (default: ./models)
export MODELS_DIR="./models"
```

## üöÄ Running Tests

### Initial Setup (Once)

```bash
# Activate virtual environment
source .venv/bin/activate

# Install ML dependencies
pip install -r ml/requirements.txt

# Start database
docker-compose up -d db
```

### Test Execution

#### All ML Tests

```bash
# No need to export PYTHONPATH anymore!
# conftest.py handles this automatically
pytest ml/tests --cov=ml --cov-report=term --cov-report=xml
```

#### Specific Tests

```bash
# Basic tests only
pytest ml/tests/test_ml.py -v

# Extended tests only
pytest ml/tests/test_ml_extended.py -v

# Advanced tests only (Informer)
pytest ml/tests/test_ml_advanced.py -v

# Exclude Informer tests (faster)
pytest ml/tests -k 'not informer' -v
```

#### Tests with Detailed Coverage

```bash
pytest ml/tests \
  --cov=ml \
  --cov-report=term-missing \
  --cov-report=html \
  --cov-report=xml \
  -v
```

## üìä What Is Tested

### Basic Tests (`test_ml.py`)

- ‚úÖ Database connection (PostgreSQL/TimescaleDB)
- ‚úÖ RandomForest model training
- ‚úÖ Model saving and persistence (.pkl)
- ‚úÖ Trained model prediction

### Extended Tests (`test_ml_extended.py`)

- ‚úÖ RSI (Relative Strength Index) calculation
- ‚úÖ Technical features generation (`make_features`)
- ‚úÖ ML module imports
- ‚úÖ Environment variable validation
- ‚úÖ Directory structure verification
- ‚úÖ Threshold evaluation tests (when schema available)

### Advanced Tests (`test_ml_advanced.py`)

- ‚úÖ Time series sequence creation (Informer)
- ‚úÖ Feature engineering for time series models
- ‚úÖ Edge cases (RSI, constant prices, NaN handling)
- ‚úÖ Comprehensive feature engineering
- ‚úÖ NaN propagation
- ‚úÖ Training reproducibility
- ‚úÖ Model persistence
- ‚úÖ Feature engineering performance (benchmark < 5s for 10k rows)

## üìà Current Coverage

### Test Statistics

- **Total Tests**: 19 passed, 1 skipped
- **ML Coverage**: ~22% (improved from ~6% initial)
- **Execution Time**: ~6-10 minutes (including Informer tests)

### Covered Files

```
ml/worker/train.py           # DB engine and training functions
ml/prepare_dataset.py        # RSI, technical features
ml/train_informer_advanced.py # Sequences, Informer features
ml/eval_threshold.py         # Metrics and thresholds (skip if schema absent)
```

### Generated Reports

- `coverage.xml` - XML for CI/CD integration
- `htmlcov/` - Interactive HTML report
- Terminal - Summary with missing lines

## üîÑ Implemented Improvements

### 1. Training Module Refactoring

**File**: `ml/worker/train.py`

**Original Problem**:

- Database read and training executed on import
- Side effects caused test errors
- Engine created even when not needed

**Solution**:

```python
# Before (execution on import)
df = pd.read_sql("SELECT * FROM trainset_m1", engine)
X = df[...].fillna(0)
m.fit(X, y)

# After (lazy execution)
def load_dataset(engine_):
    """Load dataset only when explicitly called."""
    return pd.read_sql("SELECT * FROM trainset_m1", engine_)

def train_and_save(df_local: pd.DataFrame) -> str:
    """Train and save model, return path."""
    # Training logic

def main():
    df = load_dataset(engine)
    train_and_save(df)
```

**Benefits**:

- ‚úÖ Fast import without side effects
- ‚úÖ Engine available for tests (`from ml.worker.train import engine`)
- ‚úÖ Functions testable in isolation
- ‚úÖ Explicit control of when to train

### 2. Automatic Import Configuration

**File**: `ml/tests/conftest.py`

**Original Problem**:

- Required `export PYTHONPATH=.` before each test
- Imports failed: `ModuleNotFoundError: No module named 'ml'`

**Solution**:

```python
"""
ML package test configuration.

Inserts repository root into sys.path to enable absolute imports
like `from ml.worker.train import engine` without needing to export PYTHONPATH.
"""
import os
import sys

def _ensure_repo_root_on_path() -> None:
    tests_dir = os.path.dirname(os.path.abspath(__file__))
    repo_root = os.path.abspath(os.path.join(tests_dir, os.pardir, os.pardir))
    if repo_root not in sys.path:
        sys.path.insert(0, repo_root)

_ensure_repo_root_on_path()
```

**Benefits**:

- ‚úÖ Tests work directly: `pytest ml/tests`
- ‚úÖ No need to configure `PYTHONPATH`
- ‚úÖ Compatible with IDEs and CI/CD
- ‚úÖ Absolute imports work automatically

### 3. Complete ML Dependencies Installation

**Action**: Installation of `ml/requirements.txt` with torch

```bash
pip install -r ml/requirements.txt --extra-index-url https://download.pytorch.org/whl/cpu
```

**Installed Packages**:

- torch >= 2.0.0 (CPU version for CI/tests)
- All NVIDIA CUDA dependencies (for GPU environments)
- triton (kernel optimizations)

**Benefits**:

- ‚úÖ Advanced Informer tests work
- ‚úÖ Complete model available for development
- ‚úÖ CI can run complete suite

## üêõ Known Issues and Solutions

### Skipped Test: `test_eval_threshold_imports`

**Status**: Conditional skip when schema doesn't exist

**Reason**: Tables `features_h1` and `labels_h1` may not exist in empty database

**Solution**:

```python
@pytest.mark.skipif(
    not _check_db_tables_exist(),
    reason="Schema features_h1/labels_h1 doesn't exist in database",
)
def test_eval_threshold_imports():
    from ml.eval_threshold import calculate_metrics
```

**How to Fix**:

1. Populate database with historical data
2. Run `prepare_dataset.py` to create features
3. Re-run tests: skip will be automatically removed

### Deprecation Warnings

**Source**: SQLAlchemy 2.0 and numpy

**Status**: Non-blocking, informational only

**Action**: Can be suppressed with `--disable-warnings` or fixed in future sprint

## üéØ Next Steps

### Short Term

1. **Lint and Type Check**
   - Run `ruff check --fix ml` to fix imports
   - Run `mypy ml` for type validation
   - Integrate into CI for automatic enforcement

2. **Documentation Updates**
   - Remove obsolete `PYTHONPATH` instructions
   - Add troubleshooting guide
   - Document use cases for each test suite

3. **API Tests**
   - Create `api/tests/test_integration.py`
   - Test endpoints `/health`, `/predict`, `/signals`
   - Integrate with same test database
   - Add to CI

### Medium Term

1. **Coverage Expansion**
   - Goal: 60%+ ML coverage
   - Add tests for `train_model.py`
   - Test scheduler and workers
   - Validate complete end-to-end pipeline

2. **CI/CD Enhancement**
   - Coverage badge in README
   - Integration with Codecov/Coveralls
   - Parallel tests for speed
   - Torch dependency caching

3. **Performance Testing**
   - Training benchmarks
   - API load tests
   - Memory/CPU usage validation
